{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading and Exploring the Mnist Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Mnist training and test data using Pandas\n",
    "train = pd.read_csv(r\"train.csv\")  # Read the training data from the \"train.csv\" file\n",
    "test = pd.read_csv(r\"test.csv\")    # Read the test data from the \"test.csv\" file\n",
    "\n",
    "# Displaying the training data\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "27995       0       0       0       0       0       0       0       0       0   \n",
       "27996       0       0       0       0       0       0       0       0       0   \n",
       "27997       0       0       0       0       0       0       0       0       0   \n",
       "27998       0       0       0       0       0       0       0       0       0   \n",
       "27999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "27995       0  ...         0         0         0         0         0   \n",
       "27996       0  ...         0         0         0         0         0   \n",
       "27997       0  ...         0         0         0         0         0   \n",
       "27998       0  ...         0         0         0         0         0   \n",
       "27999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "27995         0         0         0         0         0  \n",
       "27996         0         0         0         0         0  \n",
       "27997         0         0         0         0         0  \n",
       "27998         0         0         0         0         0  \n",
       "27999         0         0         0         0         0  \n",
       "\n",
       "[28000 rows x 784 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting labels and features from the training data\n",
    "y_train = train['label'].values    # Extracting the 'label' column from the training data as the target labels\n",
    "X_train = train.drop(columns=['label']).values / 255  # Extracting features by dropping the 'label' column and scaling pixel values to [0, 1]\n",
    "\n",
    "# Preparing test data for prediction\n",
    "X_test = test.values / 255  # Scaling pixel values of test data to [0, 1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing Explanation:\n",
    "- 'y_train' contains the target labels for the training data. It is extracted from the 'label' column of the 'train' DataFrame using the 'values' attribute, which converts it to a NumPy array.\n",
    "\n",
    "- 'X_train' contains the features for the training data. To obtain the features, we drop the 'label' column from the 'train' DataFrame using the 'drop' method and convert the resulting DataFrame to a NumPy array using the 'values' attribute. Additionally, we scale the pixel values to the range [0, 1] by dividing by 255. This normalization is common in image data to make computations more efficient for neural networks.\n",
    "\n",
    "- 'X_test' contains the features for the test data. Similarly, we scale the pixel values of the test data to the range [0, 1] using the same normalization applied to the training data.\n",
    "\n",
    "At this point, the data preprocessing steps include splitting the data into features and labels and normalizing the pixel values. The next steps would involve building a neural network model, training it using 'X_train' and 'y_train', and then making predictions on the test data 'X_test'."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing Random Images and Their Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a 2x5 grid of subplots and set the figure size to (12, 5)\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "\n",
    "# Flatten the axes array to a 1-dimensional array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Generate 10 random indices between 0 and 41999 to select random images from the dataset\n",
    "idx = np.random.randint(0, 42000, size=10)\n",
    "\n",
    "# Loop through each of the 10 subplots to display the images and their labels\n",
    "for i in range(10):\n",
    "    # Display the image on the i-th subplot\n",
    "    axes[i].imshow(X_train[idx[i], :].reshape(28, 28), cmap='gray')\n",
    "    \n",
    "    # Hide the axes ticks to make the plot cleaner\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    # Fetch the label for the i-th random image, convert it to an integer, and set it as the title\n",
    "    axes[i].set_title(str(int(y_train[idx[i]])), color='black', fontsize=25)\n",
    "\n",
    "# Display the entire figure with all the subplots\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Reshaping and Label Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the training and test data for convolutional neural networks (CNNs)\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)  # Reshape the feature data to a 4-dimensional array (batch_size, height, width, channels)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)    # Reshape the test data similarly\n",
    "\n",
    "# One-hot encoding the target labels for multi-class classification\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)  # Convert target labels to one-hot encoded format\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Reshaping and Label Encoding Explanation: \n",
    "- Convolutional neural networks (CNNs) expect input data in a 4-dimensional format: (batch_size, height, width, channels).\n",
    "\n",
    "- 'X_train' and 'X_test' are reshaped using the 'reshape' method to have a shape of (number_of_samples, 28, 28, 1), where 28x28 represents the image dimensions, and 1 indicates a single color channel (grayscale images).\n",
    "\n",
    "- Reshaping the data is necessary as CNNs expect image data to be in this format, allowing them to perform convolutional and pooling operations on the images.\n",
    "- 'y_train' is the target label data, and 'num_classes' is set to 10, as there are 10 different digit classes (0 to 9) in the Mnist dataset.\n",
    "\n",
    "- The 'to_categorical' function from Keras is used to convert the target labels to one-hot encoded format, which is a binary representation of the classes. Each label is transformed into a binary vector of length 10, with a 1 at the index corresponding to the correct class and 0s elsewhere.\n",
    "\n",
    "- One-hot encoding is commonly used for multi-class classification tasks, as it provides a suitable representation for training a neural network to predict multiple classes.\n",
    "\n",
    "After these preprocessing steps, the data is now ready for building and training a CNN for the digit recognizer Mnist data project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try a Simple Deep Neural Network (DNN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining a Deep Neural Network (DNN) Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Deep Neural Network (DNN) model using Keras Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),        # Input layer: Flatten the 28x28 image into a 1-dimensional array\n",
    "    tf.keras.layers.Dense(256, \"relu\"),   # Hidden layer with 256 neurons and ReLU activation function\n",
    "    tf.keras.layers.Dense(128, \"relu\"),   # Hidden layer with 128 neurons and ReLU activation function\n",
    "    tf.keras.layers.Dense(10, \"softmax\")  # Output layer with 10 neurons (one for each digit class) and softmax activation function\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- In this cell, we define a deep neural network (DNN) model using the Keras Sequential API.\n",
    "- The model consists of three layers: the input layer, two hidden layers, and the output layer.\n",
    "- The `tf.keras.layers.Flatten()` layer serves as the input layer. It is used to convert the 28x28 image data (after preprocessing) into a 1-dimensional array of 784 elements (28 * 28), which is needed as input for the subsequent dense (fully connected) layers.\n",
    "- The first hidden layer is defined using `tf.keras.layers.Dense(256, \"relu\")`, which consists of 256 neurons and uses the ReLU (Rectified Linear Unit) activation function. ReLU is a popular activation function that introduces non-linearity to the model, allowing it to learn complex patterns in the data.\n",
    "- The second hidden layer is defined using `tf.keras.layers.Dense(128, \"relu\")`, which consists of 128 neurons and also uses the ReLU activation function.\n",
    "- The output layer is defined using `tf.keras.layers.Dense(10, \"softmax\")`. This dense layer consists of 10 neurons, corresponding to the 10 possible digit classes (0 to 9) in the Mnist dataset. The softmax activation function is used in the output layer for multi-class classification problems. It converts the raw model outputs into probabilities, representing the likelihood of each class. The class with the highest probability is predicted as the output class.\n",
    "\n",
    "This DNN model is a basic architecture for the digit recognizer Mnist data project. Next steps involve compiling the model with an appropriate optimizer and loss function, and then training the model using the training data `X_train` and `y_train`. After training, the model can be evaluated using the test data `X_test` to assess its performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling the Deep Neural Network (DNN) Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the Deep Neural Network (DNN) model\n",
    "model.compile(\n",
    "    optimizer='adam',                        # Adam optimizer is used for training the model\n",
    "    loss='categorical_crossentropy',         # Categorical cross-entropy loss function for multi-class classification\n",
    "    metrics=[\"accuracy\"]                     # Evaluation metric - accuracy, to monitor the model's performance\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the Deep Neural Network (DNN) Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1313/1313 [==============================] - 5s 3ms/step - loss: 0.2358 - accuracy: 0.9284\n",
      "Epoch 2/15\n",
      "1313/1313 [==============================] - 3s 3ms/step - loss: 0.0962 - accuracy: 0.9700\n",
      "Epoch 3/15\n",
      "1313/1313 [==============================] - 3s 3ms/step - loss: 0.0640 - accuracy: 0.9800\n",
      "Epoch 4/15\n",
      "1313/1313 [==============================] - 3s 3ms/step - loss: 0.0460 - accuracy: 0.9846\n",
      "Epoch 5/15\n",
      "1313/1313 [==============================] - 3s 3ms/step - loss: 0.0371 - accuracy: 0.9879\n",
      "Epoch 6/15\n",
      "1313/1313 [==============================] - 3s 2ms/step - loss: 0.0298 - accuracy: 0.9901\n",
      "Epoch 7/15\n",
      "1313/1313 [==============================] - 3s 2ms/step - loss: 0.0242 - accuracy: 0.9921\n",
      "Epoch 8/15\n",
      "1313/1313 [==============================] - 4s 3ms/step - loss: 0.0220 - accuracy: 0.9928\n",
      "Epoch 9/15\n",
      "1313/1313 [==============================] - 3s 2ms/step - loss: 0.0164 - accuracy: 0.9947\n",
      "Epoch 10/15\n",
      "1313/1313 [==============================] - 3s 2ms/step - loss: 0.0207 - accuracy: 0.9928\n",
      "Epoch 11/15\n",
      "1313/1313 [==============================] - 4s 3ms/step - loss: 0.0147 - accuracy: 0.9950\n",
      "Epoch 12/15\n",
      "1313/1313 [==============================] - 4s 3ms/step - loss: 0.0134 - accuracy: 0.9954\n",
      "Epoch 13/15\n",
      "1313/1313 [==============================] - 4s 3ms/step - loss: 0.0155 - accuracy: 0.9948\n",
      "Epoch 14/15\n",
      "1313/1313 [==============================] - 4s 3ms/step - loss: 0.0123 - accuracy: 0.9959\n",
      "Epoch 15/15\n",
      "1313/1313 [==============================] - 4s 3ms/step - loss: 0.0110 - accuracy: 0.9967\n"
     ]
    }
   ],
   "source": [
    "# Training the Deep Neural Network (DNN) model on the training data\n",
    "history = model.fit(\n",
    "    X_train,              # Input features (training data)\n",
    "    y_train,              # Target labels (one-hot encoded) corresponding to the training data\n",
    "    epochs=15             # Number of epochs (iterations) for training the model\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making Predictions using the Deep Neural Network (DNN) Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions using the Deep Neural Network (DNN) model on the test data\n",
    "DNN_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# Displaying the predicted digit classes for the test data\n",
    "DNN_pred\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating and Saving DNN Model Predictions for Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageId  Label\n",
       "0            1      2\n",
       "1            2      0\n",
       "2            3      9\n",
       "3            4      9\n",
       "4            5      3\n",
       "...        ...    ...\n",
       "27995    27996      9\n",
       "27996    27997      7\n",
       "27997    27998      3\n",
       "27998    27999      9\n",
       "27999    28000      2\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the sample_submission.csv file into a DataFrame\n",
    "sample_submission = pd.read_csv(r\"sample_submission.csv\")\n",
    "\n",
    "# Assigning the DNN model predictions to the \"Label\" column in the DataFrame\n",
    "sample_submission[\"Label\"] = DNN_pred\n",
    "\n",
    "# Saving the DataFrame to a new CSV file named \"DNN_submission.csv\" without including the index column\n",
    "sample_submission.to_csv(\"DNN_submission.csv\", index=False)\n",
    "\n",
    "# Displaying the DataFrame with the updated predictions\n",
    "sample_submission\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submitting this to the Competition, it will score around 0.97 Not good enough!!\n",
    "\n",
    "**Now let's try CNN**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional Neural Network (CNN) Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Convolutional Neural Network (CNN) model using Keras Sequential API\n",
    "cnn_model = tf.keras.models.Sequential([\n",
    "    # First convolutional layer with 32 filters, each of size (3, 3), using ReLU activation function\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    # Max pooling layer with pool size (2, 2) to downsample the feature maps\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    # Second convolutional layer with 64 filters, each of size (3, 3), using ReLU activation function\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    # Max pooling layer with pool size (2, 2) to downsample the feature maps further\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    # Flatten the 2D feature maps to feed into a Dense (fully connected) layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # First Dense (fully connected) layer with 256 neurons and ReLU activation function\n",
    "    tf.keras.layers.Dense(256, \"relu\"),\n",
    "    # Second Dense (fully connected) layer with 128 neurons and ReLU activation function\n",
    "    tf.keras.layers.Dense(128, \"relu\"),\n",
    "    \n",
    "    # Output layer with 10 neurons (one for each digit class) and softmax activation function\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- In this cell, we define a convolutional neural network (CNN) model using the Keras Sequential API.\n",
    "- The model consists of multiple layers, starting with two convolutional layers, followed by max-pooling layers, and then two fully connected (Dense) layers, and finally an output layer.\n",
    "- The first convolutional layer uses `tf.keras.layers.Conv2D(32, (3, 3), activation='relu')`. It has 32 filters (also known as channels) of size (3, 3) and uses the ReLU activation function, which introduces non-linearity to the model. This layer is designed to extract important features from the input images.\n",
    "- After the first convolutional layer, we add a max-pooling layer using `tf.keras.layers.MaxPooling2D(2, 2)`. This layer performs downsampling, reducing the spatial dimensions of the feature maps obtained from the previous convolutional layer. It helps in reducing the computational complexity while retaining the important information.\n",
    "- The second convolutional layer uses `tf.keras.layers.Conv2D(64, (3, 3), activation='relu')`. Similar to the first layer, it has 64 filters of size (3, 3) and uses the ReLU activation function.\n",
    "- Another max-pooling layer is added after the second convolutional layer, again using `tf.keras.layers.MaxPooling2D(2, 2)`.\n",
    "- The feature maps obtained from the last max-pooling layer are then flattened using `tf.keras.layers.Flatten()`, converting them into a 1-dimensional array suitable for the fully connected layers.\n",
    "- The first fully connected (Dense) layer with 256 neurons is defined using `tf.keras.layers.Dense(256, \"relu\")`, which uses the ReLU activation function.\n",
    "- The second fully connected (Dense) layer with 128 neurons is defined using `tf.keras.layers.Dense(128, \"relu\")`, also using the ReLU activation function.\n",
    "- Finally, the output layer with 10 neurons (one for each digit class) is defined using `tf.keras.layers.Dense(10, activation='softmax')`. The softmax activation function is used to convert the raw model outputs into probabilities, representing the likelihood of each class. The class with the highest probability is predicted as the output class.\n",
    "\n",
    "This CNN model is a suitable architecture for the digit recognizer Mnist data project. The next steps would involve compiling the model with an appropriate optimizer and loss function, training it using the training data `X_train` and `y_train`, and then evaluating its performance using the test data `X_test`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling the Convolutional Neural Network (CNN) Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the Convolutional Neural Network (CNN) model\n",
    "cnn_model.compile(\n",
    "    optimizer='adam',                          # Adam optimizer is used for training the model\n",
    "    loss='categorical_crossentropy',           # Categorical cross-entropy loss function for multi-class classification\n",
    "    metrics=[\"accuracy\"]                       # Evaluation metric - accuracy, to monitor the model's performance\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- In this cell, we compile the convolutional neural network (CNN) model using the `compile` method.\n",
    "- The `optimizer` is set to `'adam'`, which stands for Adaptive Moment Estimation. Adam is a popular optimization algorithm used for training deep learning models. It combines the benefits of both RMSprop and momentum methods to efficiently update the model parameters during training.\n",
    "- The `loss` is set to `'categorical_crossentropy'`. As this is a multi-class classification problem, categorical cross-entropy is a suitable loss function. It measures the dissimilarity between the predicted class probabilities and the true one-hot encoded labels. The goal of the model during training is to minimize this loss function, effectively learning to make accurate predictions.\n",
    "- We specify the `metrics` as `[\"accuracy\"]`. This indicates that we want to monitor the accuracy of the model during training and evaluation. Accuracy measures the proportion of correct predictions made by the model over the total number of samples. It is a common evaluation metric for classification tasks.\n",
    "\n",
    "After compiling the model, the next step would be to train it on the training data using the `fit` method with the appropriate hyperparameters, such as the number of epochs and batch size. After training, the model's performance can be assessed using the test data to evaluate its ability to recognize handwritten digits."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the Convolutional Neural Network (CNN) Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 31s 15ms/step - loss: 0.1278 - accuracy: 0.9606\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0424 - accuracy: 0.9869\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0308 - accuracy: 0.9908\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0219 - accuracy: 0.9931\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0172 - accuracy: 0.9944\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0143 - accuracy: 0.9956\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0122 - accuracy: 0.9963\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0097 - accuracy: 0.9973\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0089 - accuracy: 0.9973\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0087 - accuracy: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x295a504bf90>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Convolutional Neural Network (CNN) model on the training data\n",
    "cnn_model.fit(\n",
    "    X_train,                # Input features (training data)\n",
    "    y_train,                # Target labels (one-hot encoded) corresponding to the training data\n",
    "    epochs=10               # Number of epochs (iterations) for training the model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional Neural Network (CNN) Model Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_58 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 256)               409856    \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 462,858\n",
      "Trainable params: 462,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making Predictions using the Convolutional Neural Network (CNN) Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 4s 4ms/step\n",
      "[2 0 9 ... 3 9 2]\n"
     ]
    }
   ],
   "source": [
    "cnn_pred = np.argmax(cnn_model.predict(X_test),axis=1)\n",
    "\n",
    "print(cnn_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating and Saving CNN Model Predictions for Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageId  Label\n",
       "0            1      2\n",
       "1            2      0\n",
       "2            3      9\n",
       "3            4      9\n",
       "4            5      3\n",
       "...        ...    ...\n",
       "27995    27996      9\n",
       "27996    27997      7\n",
       "27997    27998      3\n",
       "27998    27999      9\n",
       "27999    28000      2\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the sample_submission.csv file into a DataFrame\n",
    "sample_submission = pd.read_csv(r\"sample_submission.csv\")\n",
    "\n",
    "# Assigning the CNN model predictions to the \"Label\" column in the DataFrame\n",
    "sample_submission[\"Label\"] = cnn_pred\n",
    "\n",
    "# Saving the DataFrame to a new CSV file named \"CNN_submission.csv\" without including the index column\n",
    "sample_submission.to_csv(\"CNN_submission.csv\", index=False)\n",
    "\n",
    "# Displaying the DataFrame with the updated predictions\n",
    "sample_submission\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model Predictions for Submission\n",
    "\n",
    "Congratulations! ðŸŽ‰ Our Convolutional Neural Network (CNN) model has achieved remarkable success, boasting an outstanding 99% accuracy on image classification for the Mnist dataset.\n",
    "\n",
    "#### How It Was Accomplished\n",
    "By employing convolutional layers to extract essential features and pooling layers to downsample the feature maps, our CNN model was able to discern handwritten digits with exceptional precision.\n",
    "\n",
    "#### Kaggle Competition Submission\n",
    "We have generated a CSV file named \"CNN_submission.csv\" containing our model's digit class predictions. This file is formatted to meet the Kaggle competition's requirements.\n",
    "\n",
    "#### Model Performance\n",
    "Our model's ability to achieve such high accuracy on image classification tasks showcases the immense potential of deep learning techniques for computer vision applications.\n",
    "\n",
    "Stay tuned as we continue to explore the exciting world of machine learning and artificial intelligence!\n",
    "\n",
    "Cheers! ðŸš€\n",
    "\n",
    "[Moaz Eldsouky]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving the Trained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"digit_recognizer_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
